# ğŸš€ GuÃ­a RÃ¡pida de Uso - Control de Dron con Gestos

## âš¡ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Clonar repositorio
git clone <tu-repositorio>
cd AI-Flying-drone

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
pip install torchsummary  # Para visualizaciÃ³n de arquitecturas
```

### 2. Verificar InstalaciÃ³n

```bash
python -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

---

## ğŸ“Š Flujo Completo del Proyecto

### Paso 1: Grabar Dataset (Si no tienes datos)

```bash
python main.py --mode record
```

**Controles:**
- `0-9`: Seleccionar clase de gesto
- `ESPACIO`: Iniciar/Pausar grabaciÃ³n
- `S`: Guardar estadÃ­sticas
- `Q`: Salir

**Recomendaciones:**
- Grabar 8-10 minutos por gesto
- Variar iluminaciÃ³n, distancia y Ã¡ngulos
- Total: ~1.5-2 horas

---

### Paso 2: Visualizar Arquitecturas (Opcional)

```bash
# Ver todas las arquitecturas
python visualize_architectures.py

# Ver arquitectura especÃ­fica
python visualize_architectures.py --model resnet18
python visualize_architectures.py --model temporal
```

**Outputs:**
- Diagramas PNG en `/results/architectures/`
- Resumen en texto: `architectures_summary.txt`

---

### Paso 3: Entrenar y Comparar Clasificadores

```bash
# Entrenamiento completo (100 Ã©pocas, ~4-5 horas)
python train_classifier_compare.py

# Modo rÃ¡pido para pruebas (10 Ã©pocas, ~30 min)
python train_classifier_compare.py --quick

# Entrenar solo modelos especÃ­ficos
python train_classifier_compare.py --models resnet18 mobilenetv3_small
```

**Lo que hace:**
1. Entrena 4 modelos: ResNet18, ResNet34, MobileNetV3-Large, MobileNetV3-Small
2. Registra mÃ©tricas completas (train/val/test) por Ã©poca
3. Calcula Overfitting Score y Performance Score
4. Selecciona automÃ¡ticamente el mejor modelo
5. Genera grÃ¡ficos comparativos

**Outputs:**
- Checkpoints: `/checkpoints/classifier_<modelo>_best.pt`
- MÃ©tricas: `/results/classifier_<modelo>_*_metrics.json`
- ComparaciÃ³n: `/results/model_comparison_results.json`
- GrÃ¡ficos:
  - `comparison_training_curves.png`
  - `comparison_final_metrics.png`

**CÃ³mo interpretar resultados:**
```json
{
  "best_model": {
    "model": "resnet18",              // Mejor modelo seleccionado
    "test_acc": 0.9650,               // Accuracy en test
    "overfitting_score": 0.0234,      // Diferencia train-val (menor mejor)
    "performance_score": 0.9584       // Score combinado (mayor mejor)
  }
}
```

---

### Paso 4: Entrenar Red Temporal GRU

```bash
# Usar el mejor clasificador del paso anterior
python train_temporal.py --epochs 100 --batch_size 32
```

**ConfiguraciÃ³n:**
- 30 frames por secuencia (1 segundo @ 30fps)
- GRU unidireccional
- Outputs: Gesto + Intensidad (0-1)

**Outputs:**
- Checkpoint: `/checkpoints/temporal_gru_best.pt`
- MÃ©tricas: `/results/temporal_gru_metrics.json`

---

### Paso 5: Probar el Sistema

#### OpciÃ³n A: Solo Simulador (control por teclado)

```bash
python main.py --mode simulator
```

**Controles:**
- `W/S`: Adelante/AtrÃ¡s
- `A/D`: Izquierda/Derecha
- `Q/E`: Rotar
- `SPACE/SHIFT`: Subir/Bajar
- `H`: Hover
- `X`: Emergencia
- `R`: Reset
- `ESC`: Salir

#### OpciÃ³n B: Demo de Inferencia (gestos con webcam)

```bash
python main.py --mode demo
```

Muestra detecciÃ³n de gestos en tiempo real.

#### OpciÃ³n C: Sistema Integrado (gestos â†’ dron)

```bash
python main.py --mode integrated
```

Controla el dron con gestos de mano capturados por webcam.

---

## ğŸ® Gestos Disponibles

| Gesto | Comando | AcciÃ³n |
|-------|---------|--------|
| âœ‹ Palma adelante | PITCH_FORWARD | Adelante |
| ğŸ–ï¸ Palma vertical | PITCH_BACKWARD | AtrÃ¡s |
| âœŒï¸ V-dedos derecha | ROLL_RIGHT | Derecha |
| âœŒï¸ V-dedos izquierda | ROLL_LEFT | Izquierda |
| ğŸ‘ Pulgar arriba | THROTTLE_UP | Subir |
| ğŸ‘ Pulgar abajo | THROTTLE_DOWN | Bajar |
| ğŸ¤™ Shaka derecha | YAW_RIGHT | Rotar derecha |
| ğŸ¤™ Shaka izquierda | YAW_LEFT | Rotar izquierda |
| âœŠ PuÃ±o cerrado | HOVER | Mantener posiciÃ³n |
| ğŸ–– Vulcano | EMERGENCY_STOP | Emergencia |

---

## ğŸ“ˆ Monitoreo de Entrenamiento

### Durante el Entrenamiento

Terminal muestra:
```
Ã‰poca 1/100
----------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:23<00:00]  loss: 1.2345, acc: 0.8234
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:03<00:00]
  Train - Loss: 1.2345, Acc: 0.8234
  Val   - Loss: 0.9876, Acc: 0.8567
  LR: 0.001000
```

### DespuÃ©s del Entrenamiento

Revisar:
1. **Logs**: `/logs/`
2. **Checkpoints**: `/checkpoints/`
3. **Resultados**: `/results/`
4. **GrÃ¡ficos**: Abrir PNG en `/results/`

---

## ğŸ¨ Nuevo Simulador Mejorado

### CaracterÃ­sticas Visuales

1. **Paisaje**:
   - Cielo celeste
   - MontaÃ±as de fondo
   - Suelo de cÃ©sped verde

2. **Entorno**:
   - 12 Ã¡rboles distribuidos
   - 3 edificios/torres de control
   - Ejes de coordenadas con flechas

3. **Dron**:
   - OrientaciÃ³n corregida (frente hacia adelante)
   - Marcadores rojos en el frente
   - HÃ©lices animadas

### CÃ¡mara

- Sigue al dron automÃ¡ticamente
- Vista desde atrÃ¡s y arriba
- Distancia: 15 unidades
- Altura: 8 unidades

---

## âš™ï¸ ConfiguraciÃ³n Personalizada

Editar `config.py`:

```python
# Entrenamiento
TRAINING_CONFIG = {
    "cls_epochs": 100,        # NÃºmero de Ã©pocas
    "cls_batch_size": 256,    # TamaÃ±o de batch (reducir si OOM)
    "cls_lr": 1e-3,           # Learning rate inicial
    "patience": 20,           # Early stopping
}

# Temporal
TEMPORAL_CONFIG = {
    "sequence_length": 30,    # Frames por secuencia
    "hidden_size": 256,       # TamaÃ±o del GRU
    "bidirectional": False,   # Unidireccional
}

# CÃ¡mara
CAMERA_CONFIG = {
    "camera_id": 0,           # ID de webcam
    "frame_width": 640,
    "frame_height": 480,
}
```

---

## ğŸ› Problemas Comunes

### CUDA out of memory

**SÃ­ntoma:** `RuntimeError: CUDA out of memory`

**SoluciÃ³n:**
```python
# En config.py
TRAINING_CONFIG = {
    "cls_batch_size": 128,  # O 64
}
```

### Webcam no funciona

**SÃ­ntoma:** `No camera found`

**SoluciÃ³n:**
```python
# En config.py
CAMERA_CONFIG = {
    "camera_id": 1,  # Probar 0, 1, 2...
}
```

### OpenGL no funciona

**SÃ­ntoma:** Ventana negra o error de OpenGL

**SoluciÃ³n:**
```bash
python drone_simulator.py --2d
```

### Baja precisiÃ³n de gestos

**SoluciÃ³n:**
1. Grabar mÃ¡s datos (8-10 min por gesto)
2. Variar condiciones (luz, distancia, Ã¡ngulo)
3. Aumentar Ã©pocas de entrenamiento
4. Ajustar `confidence_threshold` en config.py

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### Clasificador

âœ… **Excelente**: Test Acc > 95%, Overfitting < 0.05
âœ… **Bueno**: Test Acc > 90%, Overfitting < 0.10
âš ï¸ **Mejorable**: Test Acc < 90% o Overfitting > 0.10

### Red Temporal

âœ… **Excelente**: Test Acc > 93%
âœ… **Bueno**: Test Acc > 88%
âš ï¸ **Mejorable**: Test Acc < 88%

### Sistema Completo

âœ… **Excelente**: FPS â‰¥ 25, Latencia < 80ms
âœ… **Bueno**: FPS â‰¥ 20, Latencia < 100ms
âš ï¸ **Mejorable**: FPS < 20 o Latencia > 100ms

---

## ğŸ¯ Tips para Mejores Resultados

### Dataset

1. **Calidad sobre cantidad**: Mejor 5 min de datos variados que 30 min monÃ³tonos
2. **IluminaciÃ³n variada**: Natural, artificial, mixta
3. **Distancias**: 50cm, 1m, 1.5m
4. **Ãngulos**: Frontal, ligeramente lateral
5. **Fondos**: Limpios y variados

### Entrenamiento

1. **Monitorear overfitting**: Si train >> val, necesitas mÃ¡s datos o regularizaciÃ³n
2. **Learning rate**: Si no converge, reducir LR inicial
3. **Early stopping**: Si se activa muy pronto, aumentar paciencia
4. **Batch size**: Mayor batch = entrenamiento mÃ¡s estable pero mÃ¡s lento

### Inferencia

1. **IluminaciÃ³n**: Consistente, evitar sombras fuertes
2. **Fondo**: Lo mÃ¡s limpio posible
3. **Distancia**: 0.8-1.2m de la cÃ¡mara
4. **Mano completa**: Asegurarse que toda la mano sea visible

---

## ğŸ“ Estructura de Archivos Clave

```
AI-Flying-drone/
â”œâ”€â”€ config.py                        # âš™ï¸ ConfiguraciÃ³n principal
â”œâ”€â”€ train_classifier_compare.py     # ğŸ†• Entrenamiento comparativo
â”œâ”€â”€ visualize_architectures.py      # ğŸ†• VisualizaciÃ³n de arquitecturas
â”œâ”€â”€ train_temporal.py                # Entrenamiento GRU
â”œâ”€â”€ main.py                          # Punto de entrada principal
â”œâ”€â”€ drone_simulator.py               # ğŸ†• Simulador mejorado
â”œâ”€â”€ checkpoints/                     # Modelos entrenados
â”‚   â”œâ”€â”€ classifier_resnet18_best.pt
â”‚   â”œâ”€â”€ classifier_mobilenetv3_small_best.pt
â”‚   â””â”€â”€ temporal_gru_best.pt
â”œâ”€â”€ results/                         # GrÃ¡ficos y mÃ©tricas
â”‚   â”œâ”€â”€ model_comparison_results.json
â”‚   â”œâ”€â”€ comparison_training_curves.png
â”‚   â””â”€â”€ architectures/
â””â”€â”€ data/
    â””â”€â”€ dataset/                     # Dataset grabado
```

---

## â±ï¸ Tiempo Estimado por Tarea

| Tarea | Tiempo Estimado |
|-------|----------------|
| Grabar dataset completo | 1.5-2 horas |
| Entrenar 4 clasificadores (100 Ã©pocas) | 4-5 horas |
| Entrenar red temporal (100 Ã©pocas) | 1-2 horas |
| Visualizar arquitecturas | 5 minutos |
| Probar sistema | Variable |
| **Total (sin contar pruebas)** | **~7-9 horas** |

---

## ğŸš€ Comando Ãšnico para Entrenamiento Completo

```bash
# Entrenar clasificadores y visualizar (dejar corriendo overnight)
python train_classifier_compare.py && \
python train_temporal.py --epochs 100 && \
python visualize_architectures.py && \
echo "âœ… Entrenamiento completado!"
```

---

## ğŸ“ Siguiente Paso

DespuÃ©s de completar el entrenamiento:

1. âœ… Revisar `model_comparison_results.json`
2. âœ… Analizar grÃ¡ficos en `/results`
3. âœ… Probar mejor modelo con `python main.py --mode integrated`
4. âœ… Documentar resultados para proyecto final

---

## ğŸ“ Para el Proyecto Final

Incluir en tu reporte:

1. **ComparaciÃ³n de modelos**: Tabla de `model_comparison_results.json`
2. **GrÃ¡ficos**: `comparison_training_curves.png`, `comparison_final_metrics.png`
3. **Arquitecturas**: Diagramas de `/results/architectures/`
4. **MÃ©tricas**: Accuracy, Overfitting Score, Performance Score
5. **AnÃ¡lisis**: Â¿Por quÃ© elegiste el mejor modelo?
6. **Demo**: Video del sistema funcionando

---

**Â¡Buena suerte con tu proyecto final! ğŸšğŸ®**
